{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation Length Effect Analysis\n",
    "\n",
    "Analyzes whether context-anchoring intensifies with conversation length.\n",
    "\n",
    "**Length categories:**\n",
    "- Short: 3-5 turns (n=44)\n",
    "- Medium: 7-9 turns (n=99)\n",
    "- Long: 11+ turns (n=39)\n",
    "\n",
    "**Focus:** X→EN fidelity (where context-anchoring is most visible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T02:35:01.088630Z",
     "iopub.status.busy": "2026-02-05T02:35:01.088555Z",
     "iopub.status.idle": "2026-02-05T02:35:03.439322Z",
     "shell.execute_reply": "2026-02-05T02:35:03.438863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /Users/kyuheekim/crossturn-lang-switch\n",
      "Models: ['gpt-5', 'gemini-3-pro', 'claude-opus-4.5', 'deepseek-v3.1', 'command-r-plus']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "\n",
    "# Change to project root\n",
    "os.chdir(Path(__file__).parent.parent if '__file__' in dir() else Path.cwd().parent)\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "MODELS = {\n",
    "    'gpt-5': 'GPT-5',\n",
    "    'gemini-3-pro': 'Gemini 3 Pro',\n",
    "    'claude-opus-4.5': 'Claude Opus 4.5',\n",
    "    'deepseek-v3.1': 'DeepSeek-V3.1',\n",
    "    'command-r-plus': 'Command R+',\n",
    "}\n",
    "\n",
    "LANGS = ['de', 'zh', 'es', 'ar']\n",
    "\n",
    "def categorize_length(turns):\n",
    "    \"\"\"Categorize conversation length.\"\"\"\n",
    "    if 3 <= turns <= 5:\n",
    "        return 'Short'\n",
    "    elif 7 <= turns <= 9:\n",
    "        return 'Medium'\n",
    "    elif turns >= 11:\n",
    "        return 'Long'\n",
    "    else:\n",
    "        return None  # Exclude 2, 6, 10 turns\n",
    "\n",
    "print(f\"Models: {list(MODELS.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Turn Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T02:35:03.462586Z",
     "iopub.status.busy": "2026-02-05T02:35:03.461976Z",
     "iopub.status.idle": "2026-02-05T02:35:03.478175Z",
     "shell.execute_reply": "2026-02-05T02:35:03.477686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn Distribution in Dataset:\n",
      "========================================\n",
      "   3 turns:   7 (  3.8%) (Short)\n",
      "   5 turns:  37 ( 20.3%) (Short)\n",
      "   7 turns:  68 ( 37.4%) (Medium)\n",
      "   9 turns:  31 ( 17.0%) (Medium)\n",
      "  11 turns:  18 (  9.9%) (Long)\n",
      "  13 turns:  11 (  6.0%) (Long)\n",
      "  15 turns:   8 (  4.4%) (Long)\n",
      "  19 turns:   2 (  1.1%) (Long)\n",
      "\n",
      "Total samples: 182\n",
      "\n",
      "By category:\n",
      "  Short (3-5 turns):    44 (24.2%)\n",
      "  Medium (7-9 turns):   99 (54.4%)\n",
      "  Long (11+ turns):     39 (21.4%)\n",
      "\n",
      "By axis:\n",
      "  INSTRUCTION_RETENTION: 69\n",
      "  INFERENCE_MEMORY: 113\n",
      "\n",
      "============================================================\n",
      "Turn Distribution BY AXIS:\n",
      "============================================================\n",
      "\n",
      "INFERENCE_MEMORY (n=113):\n",
      "  Turns         Count      Pct\n",
      "------------------------------\n",
      "  3                 4     3.5%\n",
      "  5                22    19.5%\n",
      "  7                48    42.5%\n",
      "  9                17    15.0%\n",
      "  11               11     9.7%\n",
      "  13                5     4.4%\n",
      "  15                5     4.4%\n",
      "  19                1     0.9%\n",
      "\n",
      "  Category breakdown:\n",
      "    Short (3-5):    26 (23.0%)\n",
      "    Medium (7-9):   65 (57.5%)\n",
      "    Long (11+):     22 (19.5%)\n",
      "\n",
      "INSTRUCTION_RETENTION (n=69):\n",
      "  Turns         Count      Pct\n",
      "------------------------------\n",
      "  3                 3     4.3%\n",
      "  5                15    21.7%\n",
      "  7                20    29.0%\n",
      "  9                14    20.3%\n",
      "  11                7    10.1%\n",
      "  13                6     8.7%\n",
      "  15                3     4.3%\n",
      "  19                1     1.4%\n",
      "\n",
      "  Category breakdown:\n",
      "    Short (3-5):    18 (26.1%)\n",
      "    Medium (7-9):   34 (49.3%)\n",
      "    Long (11+):     17 (24.6%)\n",
      "\n",
      "============================================================\n",
      "LaTeX: Turn Composition by Axis\n",
      "============================================================\n",
      "\\begin{tabular}{@{}lcccc@{}}\n",
      "\\toprule\n",
      "\\textbf{Axis} & \\textbf{n} & \\textbf{Short} & \\textbf{Medium} & \\textbf{Long} \\\\\n",
      "\\midrule\n",
      "INFERENCE\\_MEMORY & 113 & 26 & 65 & 22 \\\\\n",
      "INSTRUCTION\\_RETENTION & 69 & 18 & 34 & 17 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "# Analyze turn distribution in baseline dataset\n",
    "from collections import Counter\n",
    "\n",
    "with open('data/experiments/baseline_en.jsonl') as f:\n",
    "    data = [json.loads(l) for l in f]\n",
    "    turns = [len(d['CONVERSATION']) for d in data]\n",
    "    axes = [d['AXIS'] for d in data]\n",
    "\n",
    "print(\"Turn Distribution in Dataset:\")\n",
    "print(\"=\" * 40)\n",
    "for t, count in sorted(Counter(turns).items()):\n",
    "    pct = count / len(turns) * 100\n",
    "    cat = categorize_length(t)\n",
    "    cat_str = f\"({cat})\" if cat else \"(excluded)\"\n",
    "    print(f\"  {t:2d} turns: {count:3d} ({pct:5.1f}%) {cat_str}\")\n",
    "\n",
    "print(f\"\\nTotal samples: {len(turns)}\")\n",
    "print(f\"\\nBy category:\")\n",
    "short = sum(1 for t in turns if 3 <= t <= 5)\n",
    "medium = sum(1 for t in turns if 7 <= t <= 9)\n",
    "long = sum(1 for t in turns if t >= 11)\n",
    "print(f\"  Short (3-5 turns):   {short:3d} ({short/len(turns)*100:.1f}%)\")\n",
    "print(f\"  Medium (7-9 turns):  {medium:3d} ({medium/len(turns)*100:.1f}%)\")\n",
    "print(f\"  Long (11+ turns):    {long:3d} ({long/len(turns)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nBy axis:\")\n",
    "for axis, count in Counter(axes).items():\n",
    "    print(f\"  {axis}: {count}\")\n",
    "\n",
    "# Turn distribution by axis\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"Turn Distribution BY AXIS:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for axis in ['INFERENCE_MEMORY', 'INSTRUCTION_RETENTION']:\n",
    "    axis_data = [d for d in data if d['AXIS'] == axis]\n",
    "    axis_turns = [len(d['CONVERSATION']) for d in axis_data]\n",
    "    \n",
    "    print(f\"\\n{axis} (n={len(axis_data)}):\")\n",
    "    print(f\"  {'Turns':<10} {'Count':>8} {'Pct':>8}\")\n",
    "    print(\"-\" * 30)\n",
    "    for t, count in sorted(Counter(axis_turns).items()):\n",
    "        pct = count / len(axis_turns) * 100\n",
    "        print(f\"  {t:<10} {count:>8} {pct:>7.1f}%\")\n",
    "    \n",
    "    # By category\n",
    "    short = sum(1 for t in axis_turns if 3 <= t <= 5)\n",
    "    medium = sum(1 for t in axis_turns if 7 <= t <= 9)\n",
    "    long = sum(1 for t in axis_turns if t >= 11)\n",
    "    print(f\"\\n  Category breakdown:\")\n",
    "    print(f\"    Short (3-5):   {short:3d} ({short/len(axis_turns)*100:.1f}%)\")\n",
    "    print(f\"    Medium (7-9):  {medium:3d} ({medium/len(axis_turns)*100:.1f}%)\")\n",
    "    print(f\"    Long (11+):    {long:3d} ({long/len(axis_turns)*100:.1f}%)\")\n",
    "\n",
    "# LaTeX output for turn by axis\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"LaTeX: Turn Composition by Axis\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\\\begin{tabular}{@{}lcccc@{}}\")\n",
    "print(\"\\\\toprule\")\n",
    "print(\"\\\\textbf{Axis} & \\\\textbf{n} & \\\\textbf{Short} & \\\\textbf{Medium} & \\\\textbf{Long} \\\\\\\\\")\n",
    "print(\"\\\\midrule\")\n",
    "\n",
    "for axis in ['INFERENCE_MEMORY', 'INSTRUCTION_RETENTION']:\n",
    "    axis_data = [d for d in data if d['AXIS'] == axis]\n",
    "    axis_turns = [len(d['CONVERSATION']) for d in axis_data]\n",
    "    \n",
    "    short = sum(1 for t in axis_turns if 3 <= t <= 5)\n",
    "    medium = sum(1 for t in axis_turns if 7 <= t <= 9)\n",
    "    long = sum(1 for t in axis_turns if t >= 11)\n",
    "    \n",
    "    axis_display = axis.replace('_', '\\\\_')\n",
    "    print(f\"{axis_display} & {len(axis_data)} & {short} & {medium} & {long} \\\\\\\\\")\n",
    "\n",
    "print(\"\\\\bottomrule\")\n",
    "print(\"\\\\end{tabular}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Language Eval Results with Turn Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T02:35:03.483582Z",
     "iopub.status.busy": "2026-02-05T02:35:03.483276Z",
     "iopub.status.idle": "2026-02-05T02:35:03.496628Z",
     "shell.execute_reply": "2026-02-05T02:35:03.495992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 182 responses, 182 eval results\n"
     ]
    }
   ],
   "source": [
    "def load_responses_with_turns(model, condition):\n",
    "    \"\"\"Load responses and extract turn counts.\"\"\"\n",
    "    pattern = f'results/responses/{model}/responses_{condition}_*.jsonl'\n",
    "    files = sorted(glob.glob(pattern))\n",
    "    # Exclude variance runs (run2, run3) - only use primary results\n",
    "    files = [f for f in files if '_run2_' not in f and '_run3_' not in f]\n",
    "    if not files:\n",
    "        return None\n",
    "    \n",
    "    data = []\n",
    "    with open(files[-1]) as f:\n",
    "        for line in f:\n",
    "            item = json.loads(line.strip())\n",
    "            if item.get('success'):\n",
    "                data.append({\n",
    "                    'question_id': item.get('question_id'),\n",
    "                    'turn_count': item.get('turn_count'),\n",
    "                    'response': item.get('response', '')\n",
    "                })\n",
    "    return data\n",
    "\n",
    "def load_language_eval(model, condition):\n",
    "    \"\"\"Load language evaluation results.\"\"\"\n",
    "    pattern = f'results/layer1/{model}/language_eval_{condition}_*.jsonl'\n",
    "    files = sorted(glob.glob(pattern))\n",
    "    # Exclude variance runs (run2, run3) - only use primary results\n",
    "    files = [f for f in files if '_run2_' not in f and '_run3_' not in f]\n",
    "    if not files:\n",
    "        return None\n",
    "    \n",
    "    data = {}\n",
    "    with open(files[-1]) as f:\n",
    "        for line in f:\n",
    "            item = json.loads(line.strip())\n",
    "            qid = item.get('question_id')\n",
    "            data[qid] = item.get('match_status') == 'match'\n",
    "    return data\n",
    "\n",
    "# Test\n",
    "responses = load_responses_with_turns('gpt-5', 'de_to_en')\n",
    "lang_eval = load_language_eval('gpt-5', 'de_to_en')\n",
    "if responses and lang_eval:\n",
    "    print(f\"Loaded {len(responses)} responses, {len(lang_eval)} eval results\")\n",
    "else:\n",
    "    print(\"Data not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute Fidelity by Length for X→EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T02:35:03.502941Z",
     "iopub.status.busy": "2026-02-05T02:35:03.502698Z",
     "iopub.status.idle": "2026-02-05T02:35:03.661613Z",
     "shell.execute_reply": "2026-02-05T02:35:03.661190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X->EN Fidelity by Conversation Length\n",
      "======================================================================\n",
      "Model                    Short (3-5)    Medium (7-9)      Long (11+)\n",
      "----------------------------------------------------------------------\n",
      "GPT-5                97.2% (171/176) 93.9% (372/396) 95.5% (149/156)\n",
      "Gemini 3 Pro         82.4% (145/176) 75.0% (297/396)  60.9% (95/156)\n",
      "Claude Opus 4.5       11.9% (21/176)   5.8% (23/396)   7.7% (12/156)\n",
      "DeepSeek-V3.1         55.1% (97/176) 54.0% (214/396)  42.9% (67/156)\n",
      "Command R+              0.0% (0/176)    0.5% (2/396)    2.6% (4/156)\n"
     ]
    }
   ],
   "source": [
    "def compute_fidelity_by_length(model):\n",
    "    \"\"\"Compute X->EN fidelity by conversation length.\"\"\"\n",
    "    results = {'Short': {'match': 0, 'total': 0},\n",
    "               'Medium': {'match': 0, 'total': 0},\n",
    "               'Long': {'match': 0, 'total': 0}}\n",
    "    \n",
    "    for lang in LANGS:\n",
    "        condition = f\"{lang}_to_en\"\n",
    "        \n",
    "        responses = load_responses_with_turns(model, condition)\n",
    "        lang_eval = load_language_eval(model, condition)\n",
    "        \n",
    "        if not responses or not lang_eval:\n",
    "            continue\n",
    "        \n",
    "        for resp in responses:\n",
    "            qid = resp['question_id']\n",
    "            turns = resp['turn_count']\n",
    "            category = categorize_length(turns)\n",
    "            \n",
    "            if category and qid in lang_eval:\n",
    "                results[category]['total'] += 1\n",
    "                if lang_eval[qid]:\n",
    "                    results[category]['match'] += 1\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Compute for all models\n",
    "all_results = {}\n",
    "for model_id, model_name in MODELS.items():\n",
    "    all_results[model_id] = compute_fidelity_by_length(model_id)\n",
    "\n",
    "print(\"X->EN Fidelity by Conversation Length\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Model':<20} {'Short (3-5)':>15} {'Medium (7-9)':>15} {'Long (11+)':>15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for model_id, model_name in MODELS.items():\n",
    "    res = all_results[model_id]\n",
    "    row = []\n",
    "    for cat in ['Short', 'Medium', 'Long']:\n",
    "        if res[cat]['total'] > 0:\n",
    "            pct = res[cat]['match'] / res[cat]['total'] * 100\n",
    "            row.append(f\"{pct:.1f}% ({res[cat]['match']}/{res[cat]['total']})\")\n",
    "        else:\n",
    "            row.append(\"--\")\n",
    "    print(f\"{model_name:<20} {row[0]:>15} {row[1]:>15} {row[2]:>15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Chi-Square Tests for Length Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T02:35:03.664753Z",
     "iopub.status.busy": "2026-02-05T02:35:03.664519Z",
     "iopub.status.idle": "2026-02-05T02:35:03.671409Z",
     "shell.execute_reply": "2026-02-05T02:35:03.670906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Square Tests for Length Effect (X→EN)\n",
      "============================================================\n",
      "Model                             χ²         p-value    Significant?\n",
      "------------------------------------------------------------\n",
      "GPT-5                           2.78           0.250              No\n",
      "Gemini 3 Pro                   20.42          <0.001   Yes (p<0.001)\n",
      "Claude Opus 4.5                 6.44           0.040    Yes (p<0.05)\n",
      "DeepSeek-V3.1                   6.46           0.040    Yes (p<0.05)\n",
      "Command R+                      7.73           0.021    Yes (p<0.05)\n"
     ]
    }
   ],
   "source": [
    "def chi_square_test(results):\n",
    "    \"\"\"Run chi-square test for independence between length and fidelity.\"\"\"\n",
    "    # Build contingency table: [[match_short, match_med, match_long], [mismatch_short, ...]]\n",
    "    observed = []\n",
    "    for cat in ['Short', 'Medium', 'Long']:\n",
    "        match = results[cat]['match']\n",
    "        total = results[cat]['total']\n",
    "        if total == 0:\n",
    "            return None, None\n",
    "        observed.append([match, total - match])\n",
    "    \n",
    "    observed = np.array(observed).T  # Transpose to get 2xN matrix\n",
    "    \n",
    "    # Check if test is valid (expected counts > 5)\n",
    "    if np.any(observed.sum(axis=0) < 5):\n",
    "        return None, \"Low counts\"\n",
    "    \n",
    "    try:\n",
    "        chi2, p, dof, expected = stats.chi2_contingency(observed)\n",
    "        return chi2, p\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "print(\"Chi-Square Tests for Length Effect (X→EN)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Model':<25} {'χ²':>10} {'p-value':>15} {'Significant?':>15}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for model_id, model_name in MODELS.items():\n",
    "    res = all_results[model_id]\n",
    "    chi2, p = chi_square_test(res)\n",
    "    \n",
    "    if chi2 is not None and p is not None:\n",
    "        sig = \"Yes (p<0.001)\" if p < 0.001 else (\"Yes (p<0.05)\" if p < 0.05 else \"No\")\n",
    "        p_str = f\"<0.001\" if p < 0.001 else f\"{p:.3f}\"\n",
    "        print(f\"{model_name:<25} {chi2:>10.2f} {p_str:>15} {sig:>15}\")\n",
    "    elif p == \"Low counts\":\n",
    "        print(f\"{model_name:<25} {'--':>10} {'Low counts':>15} {'--':>15}\")\n",
    "    else:\n",
    "        print(f\"{model_name:<25} {'--':>10} {'--':>15} {'--':>15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Detailed Breakdown by Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T02:35:03.673420Z",
     "iopub.status.busy": "2026-02-05T02:35:03.673297Z",
     "iopub.status.idle": "2026-02-05T02:35:03.702299Z",
     "shell.execute_reply": "2026-02-05T02:35:03.701920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Breakdown: Claude Opus 4.5 (X->EN)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DE->EN:\n",
      "  Short: 11.4% (5/44)\n",
      "  Medium: 8.1% (8/99)\n",
      "  Long: 15.4% (6/39)\n",
      "\n",
      "ZH->EN:\n",
      "  Short: 20.5% (9/44)\n",
      "  Medium: 6.1% (6/99)\n",
      "  Long: 7.7% (3/39)\n",
      "\n",
      "ES->EN:\n",
      "  Short: 9.1% (4/44)\n",
      "  Medium: 6.1% (6/99)\n",
      "  Long: 2.6% (1/39)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AR->EN:\n",
      "  Short: 6.8% (3/44)\n",
      "  Medium: 3.0% (3/99)\n",
      "  Long: 5.1% (2/39)\n"
     ]
    }
   ],
   "source": [
    "def compute_fidelity_by_length_and_lang(model, lang):\n",
    "    \"\"\"Compute fidelity by length for specific language.\"\"\"\n",
    "    results = {'Short': {'match': 0, 'total': 0},\n",
    "               'Medium': {'match': 0, 'total': 0},\n",
    "               'Long': {'match': 0, 'total': 0}}\n",
    "    \n",
    "    condition = f\"{lang}_to_en\"\n",
    "    \n",
    "    responses = load_responses_with_turns(model, condition)\n",
    "    lang_eval = load_language_eval(model, condition)\n",
    "    \n",
    "    if not responses or not lang_eval:\n",
    "        return results\n",
    "    \n",
    "    for resp in responses:\n",
    "        qid = resp['question_id']\n",
    "        turns = resp['turn_count']\n",
    "        category = categorize_length(turns)\n",
    "        \n",
    "        if category and qid in lang_eval:\n",
    "            results[category]['total'] += 1\n",
    "            if lang_eval[qid]:\n",
    "                results[category]['match'] += 1\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Show breakdown for a specific model\n",
    "print(\"Detailed Breakdown: Claude Opus 4.5 (X->EN)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for lang in LANGS:\n",
    "    res = compute_fidelity_by_length_and_lang('claude-opus-4.5', lang)\n",
    "    print(f\"\\n{lang.upper()}->EN:\")\n",
    "    for cat in ['Short', 'Medium', 'Long']:\n",
    "        if res[cat]['total'] > 0:\n",
    "            pct = res[cat]['match'] / res[cat]['total'] * 100\n",
    "            print(f\"  {cat}: {pct:.1f}% ({res[cat]['match']}/{res[cat]['total']})\")\n",
    "        else:\n",
    "            print(f\"  {cat}: --\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LaTeX Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T02:35:03.704827Z",
     "iopub.status.busy": "2026-02-05T02:35:03.704624Z",
     "iopub.status.idle": "2026-02-05T02:35:03.709713Z",
     "shell.execute_reply": "2026-02-05T02:35:03.709124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaTeX: X->EN Fidelity by Conversation Length\n",
      "================================================================================\n",
      "GPT-5 & 97.2\\% & 93.9\\% & 95.5\\% & 0.25 \\\\\n",
      "Gemini 3 Pro & 82.4\\% & 75.0\\% & 60.9\\% & $<$0.001 \\\\\n",
      "Claude Opus 4.5 & 11.9\\% & 5.8\\% & 7.7\\% & 0.04 \\\\\n",
      "DeepSeek-V3.1 & 55.1\\% & 54.0\\% & 42.9\\% & 0.04 \\\\\n",
      "Command R+ & 0.0\\% & 0.5\\% & 2.6\\% & 0.02 \\\\\n"
     ]
    }
   ],
   "source": [
    "print(\"LaTeX: X->EN Fidelity by Conversation Length\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for model_id, model_name in MODELS.items():\n",
    "    res = all_results[model_id]\n",
    "    chi2, p = chi_square_test(res)\n",
    "    \n",
    "    vals = []\n",
    "    for cat in ['Short', 'Medium', 'Long']:\n",
    "        if res[cat]['total'] > 0:\n",
    "            pct = res[cat]['match'] / res[cat]['total'] * 100\n",
    "            vals.append(f\"{pct:.1f}\\\\%\")\n",
    "        else:\n",
    "            vals.append(\"--\")\n",
    "    \n",
    "    if p is not None and isinstance(p, float):\n",
    "        p_str = \"$<$0.001\" if p < 0.001 else f\"{p:.2f}\"\n",
    "    else:\n",
    "        p_str = \"---\"\n",
    "    \n",
    "    print(f\"{model_name} & {vals[0]} & {vals[1]} & {vals[2]} & {p_str} \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Axis Breakdown (INFERENCE_MEMORY vs INSTRUCTION_RETENTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T02:35:03.712267Z",
     "iopub.status.busy": "2026-02-05T02:35:03.712045Z",
     "iopub.status.idle": "2026-02-05T02:35:04.172780Z",
     "shell.execute_reply": "2026-02-05T02:35:04.172516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X->EN Fidelity by Axis and Conversation Length\n",
      "==========================================================================================\n",
      "\n",
      "GPT-5:\n",
      "  Axis                          Short (3-5)    Medium (7-9)      Long (11+)\n",
      "---------------------------------------------------------------------------\n",
      "  INFERENCE_MEMORY                       --              --              --\n",
      "  INSTRUCTION_RETENTION                  --              --              --\n",
      "\n",
      "Gemini 3 Pro:\n",
      "  Axis                          Short (3-5)    Medium (7-9)      Long (11+)\n",
      "---------------------------------------------------------------------------\n",
      "  INFERENCE_MEMORY                       --              --              --\n",
      "  INSTRUCTION_RETENTION                  --              --              --\n",
      "\n",
      "Claude Opus 4.5:\n",
      "  Axis                          Short (3-5)    Medium (7-9)      Long (11+)\n",
      "---------------------------------------------------------------------------\n",
      "  INFERENCE_MEMORY                       --              --              --\n",
      "  INSTRUCTION_RETENTION                  --              --              --\n",
      "\n",
      "DeepSeek-V3.1:\n",
      "  Axis                          Short (3-5)    Medium (7-9)      Long (11+)\n",
      "---------------------------------------------------------------------------\n",
      "  INFERENCE_MEMORY                       --              --              --\n",
      "  INSTRUCTION_RETENTION                  --              --              --\n",
      "\n",
      "Command R+:\n",
      "  Axis                          Short (3-5)    Medium (7-9)      Long (11+)\n",
      "---------------------------------------------------------------------------\n",
      "  INFERENCE_MEMORY                       --              --              --\n",
      "  INSTRUCTION_RETENTION                  --              --              --\n"
     ]
    }
   ],
   "source": [
    "# Load baseline data with axis info\n",
    "baseline_data = {}\n",
    "with open('data/experiments/baseline_en.jsonl') as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line.strip())\n",
    "        baseline_data[item['QUESTION_ID']] = {\n",
    "            'axis': item['AXIS'],\n",
    "            'turns': len(item['CONVERSATION'])\n",
    "        }\n",
    "\n",
    "def compute_fidelity_by_axis_and_length(model):\n",
    "    \"\"\"Compute X->EN fidelity by axis and conversation length.\"\"\"\n",
    "    results = {\n",
    "        'INFERENCE_MEMORY': {'Short': {'match': 0, 'total': 0}, \n",
    "                             'Medium': {'match': 0, 'total': 0}, \n",
    "                             'Long': {'match': 0, 'total': 0}},\n",
    "        'INSTRUCTION_RETENTION': {'Short': {'match': 0, 'total': 0}, \n",
    "                                   'Medium': {'match': 0, 'total': 0}, \n",
    "                                   'Long': {'match': 0, 'total': 0}}\n",
    "    }\n",
    "    \n",
    "    for lang in LANGS:\n",
    "        condition = f\"{lang}_to_en\"\n",
    "        \n",
    "        responses = load_responses_with_turns(model, condition)\n",
    "        lang_eval = load_language_eval(model, condition)\n",
    "        \n",
    "        if not responses or not lang_eval:\n",
    "            continue\n",
    "        \n",
    "        for resp in responses:\n",
    "            qid = resp['question_id']\n",
    "            if qid not in baseline_data or qid not in lang_eval:\n",
    "                continue\n",
    "                \n",
    "            axis = baseline_data[qid]['axis']\n",
    "            turns = resp['turn_count']\n",
    "            category = categorize_length(turns)\n",
    "            \n",
    "            if category is None:\n",
    "                continue\n",
    "            \n",
    "            results[axis][category]['total'] += 1\n",
    "            if lang_eval[qid]:\n",
    "                results[axis][category]['match'] += 1\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Compute axis breakdown for all models\n",
    "axis_results = {}\n",
    "for model_id in MODELS.keys():\n",
    "    axis_results[model_id] = compute_fidelity_by_axis_and_length(model_id)\n",
    "\n",
    "# Display results\n",
    "print(\"X->EN Fidelity by Axis and Conversation Length\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "for model_id, model_name in MODELS.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  {'Axis':<25} {'Short (3-5)':>15} {'Medium (7-9)':>15} {'Long (11+)':>15}\")\n",
    "    print(\"-\" * 75)\n",
    "    \n",
    "    for axis in ['INFERENCE_MEMORY', 'INSTRUCTION_RETENTION']:\n",
    "        res = axis_results[model_id][axis]\n",
    "        row = []\n",
    "        for cat in ['Short', 'Medium', 'Long']:\n",
    "            if res[cat]['total'] > 0:\n",
    "                pct = res[cat]['match'] / res[cat]['total'] * 100\n",
    "                row.append(f\"{pct:.1f}% ({res[cat]['match']}/{res[cat]['total']})\")\n",
    "            else:\n",
    "                row.append(\"--\")\n",
    "        print(f\"  {axis:<25} {row[0]:>15} {row[1]:>15} {row[2]:>15}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
